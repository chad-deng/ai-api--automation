#!/usr/bin/env node

import { Command } from 'commander';
import * as fs from 'fs/promises';
import * as path from 'path';
import chalk from 'chalk';
import ora from 'ora';
import Table from 'cli-table3';
import { PerformanceOptimizer, PerformanceOptimizerConfig, PerformanceOptimizationReport } from './performance-optimizer';

// CLI interface for performance optimization
export class PerformanceCLI {
  private program: Command;
  private optimizer: PerformanceOptimizer | null = null;

  constructor() {
    this.program = new Command();
    this.setupCommands();
  }

  private setupCommands(): void {
    this.program
      .name('api-test-performance')
      .description('AI API Test Automation Framework - Performance Optimization')
      .version('1.0.0');

    // Analyze command
    this.program
      .command('analyze')
      .description('Analyze current performance and identify optimization opportunities')
      .option('-c, --config <file>', 'Configuration file path')
      .option('-o, --output <directory>', 'Output directory for analysis results', './performance-analysis')
      .option('-f, --format <format>', 'Output format (json, html, text)', 'json')
      .option('--baseline <file>', 'Baseline metrics file for comparison')
      .option('--threshold <percentage>', 'Performance degradation threshold', '10')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleAnalyze(options);
      });

    // Optimize command
    this.program
      .command('optimize')
      .description('Apply performance optimizations')
      .option('-c, --config <file>', 'Configuration file path')
      .option('-o, --output <directory>', 'Output directory for optimization results', './performance-optimization')
      .option('-f, --format <format>', 'Report format (json, html, text)', 'html')
      .option('--dry-run', 'Analyze only, do not apply optimizations')
      .option('--categories <categories>', 'Optimization categories to apply (comma-separated)', 'memory,cpu,io,network,cache')
      .option('--priority <level>', 'Minimum priority level (low, medium, high, critical)', 'medium')
      .option('--max-optimizations <number>', 'Maximum number of optimizations to apply', '10')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleOptimize(options);
      });

    // Monitor command
    this.program
      .command('monitor')
      .description('Monitor performance metrics in real-time')
      .option('-c, --config <file>', 'Configuration file path')
      .option('-d, --duration <seconds>', 'Monitoring duration in seconds', '300')
      .option('-i, --interval <milliseconds>', 'Metrics collection interval', '5000')
      .option('--output <file>', 'Output file for collected metrics')
      .option('--alert-thresholds <file>', 'Alert thresholds configuration file')
      .option('--dashboard', 'Enable real-time dashboard')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleMonitor(options);
      });

    // Benchmark command
    this.program
      .command('benchmark')
      .description('Run performance benchmarks')
      .option('-c, --config <file>', 'Configuration file path')
      .option('-t, --test <pattern>', 'Test pattern to benchmark')
      .option('-n, --iterations <number>', 'Number of iterations', '5')
      .option('-w, --warmup <number>', 'Warmup iterations', '2')
      .option('-o, --output <directory>', 'Output directory for benchmark results', './performance-benchmarks')
      .option('-f, --format <format>', 'Output format (json, html, text)', 'html')
      .option('--compare <file>', 'Compare with previous benchmark results')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleBenchmark(options);
      });

    // Report command
    this.program
      .command('report')
      .description('Generate performance reports from collected data')
      .option('-i, --input <directory>', 'Input directory with performance data')
      .option('-o, --output <directory>', 'Output directory for reports', './performance-reports')
      .option('-f, --format <format>', 'Report format (json, html, pdf, markdown)', 'html')
      .option('-t, --template <name>', 'Report template (summary, detailed, executive)', 'detailed')
      .option('--compare <files...>', 'Files to compare in the report')
      .option('--time-range <range>', 'Time range for the report (1h, 1d, 1w, 1m)')
      .option('--include-recommendations', 'Include optimization recommendations')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleReport(options);
      });

    // Config command
    this.program
      .command('config')
      .description('Manage performance optimization configuration')
      .option('--init', 'Initialize default configuration')
      .option('--validate <file>', 'Validate configuration file')
      .option('--show <file>', 'Show current configuration')
      .option('--set <key=value>', 'Set configuration value')
      .option('--output <file>', 'Output file for configuration')
      .action(async (options) => {
        await this.handleConfig(options);
      });

    // Status command
    this.program
      .command('status')
      .description('Show current performance status and health')
      .option('-c, --config <file>', 'Configuration file path')
      .option('--json', 'Output in JSON format')
      .option('--verbose', 'Enable verbose output')
      .action(async (options) => {
        await this.handleStatus(options);
      });
  }

  // Handle analyze command
  private async handleAnalyze(options: any): Promise<void> {
    const spinner = ora('Analyzing performance...').start();

    try {
      // Load configuration
      const config = await this.loadConfiguration(options.config);
      this.optimizer = new PerformanceOptimizer(config);

      // Setup event listeners for progress reporting
      this.setupEventListeners(options.verbose);

      // Collect current metrics
      spinner.text = 'Collecting performance metrics...';
      await this.sleep(2000); // Allow time for metrics collection

      // Analyze performance
      spinner.text = 'Analyzing optimization opportunities...';
      const recommendations = await this.optimizer.analyzePerformance();

      spinner.succeed('Performance analysis completed');

      // Display results
      this.displayAnalysisResults(recommendations, options);

      // Save results
      await this.saveAnalysisResults(recommendations, options);

    } catch (error) {
      spinner.fail(`Analysis failed: ${error.message}`);
      process.exit(1);
    }
  }

  // Handle optimize command
  private async handleOptimize(options: any): Promise<void> {
    const spinner = ora('Optimizing performance...').start();

    try {
      // Load configuration
      const config = await this.loadConfiguration(options.config);
      
      // Filter enabled optimizations based on categories
      const categories = options.categories.split(',').map((c: string) => c.trim());
      config.general.enableOptimizations = categories;

      this.optimizer = new PerformanceOptimizer(config);

      // Setup event listeners
      this.setupEventListeners(options.verbose);

      if (options.dryRun) {
        spinner.text = 'Analyzing optimization opportunities (dry run)...';
        const recommendations = await this.optimizer.analyzePerformance();
        spinner.succeed('Dry run analysis completed');
        this.displayAnalysisResults(recommendations, options);
        return;
      }

      // Apply optimizations
      spinner.text = 'Applying performance optimizations...';
      const report = await this.optimizer.optimizePerformance();

      spinner.succeed('Performance optimization completed');

      // Display results
      this.displayOptimizationResults(report, options);

      // Save results
      await this.saveOptimizationResults(report, options);

    } catch (error) {
      spinner.fail(`Optimization failed: ${error.message}`);
      process.exit(1);
    }
  }

  // Handle monitor command
  private async handleMonitor(options: any): Promise<void> {
    console.log(chalk.blue('üìä Starting performance monitoring...'));

    try {
      // Load configuration
      const config = await this.loadConfiguration(options.config);
      this.optimizer = new PerformanceOptimizer(config);

      // Setup monitoring
      const duration = parseInt(options.duration) * 1000;
      const interval = parseInt(options.interval);

      let metricsCount = 0;
      const maxMetrics = Math.floor(duration / interval);

      this.optimizer.on('metrics-collected', (metrics) => {
        metricsCount++;
        const progress = Math.round((metricsCount / maxMetrics) * 100);
        
        if (options.dashboard) {
          this.displayDashboard(metrics, progress);
        } else {
          this.displayMetrics(metrics, progress, options.verbose);
        }
      });

      // Start monitoring
      console.log(chalk.green(`Monitoring for ${duration / 1000} seconds...`));
      console.log(chalk.gray(`Collection interval: ${interval}ms`));

      setTimeout(() => {
        console.log(chalk.green('\n‚úÖ Monitoring completed'));
        if (options.output) {
          this.optimizer?.exportPerformanceData(options.output);
          console.log(chalk.blue(`üìÅ Metrics saved to: ${options.output}`));
        }
        process.exit(0);
      }, duration);

    } catch (error) {
      console.error(chalk.red(`‚ùå Monitoring failed: ${error.message}`));
      process.exit(1);
    }
  }

  // Handle benchmark command
  private async handleBenchmark(options: any): Promise<void> {
    const spinner = ora('Running performance benchmarks...').start();

    try {
      // Load configuration
      const config = await this.loadConfiguration(options.config);
      this.optimizer = new PerformanceOptimizer(config);

      const iterations = parseInt(options.iterations);
      const warmup = parseInt(options.warmup);

      // Run warmup iterations
      if (warmup > 0) {
        spinner.text = `Running ${warmup} warmup iterations...`;
        for (let i = 0; i < warmup; i++) {
          await this.runSingleBenchmark(config);
        }
      }

      // Run benchmark iterations
      const results = [];
      for (let i = 0; i < iterations; i++) {
        spinner.text = `Running benchmark iteration ${i + 1}/${iterations}...`;
        const result = await this.runSingleBenchmark(config);
        results.push(result);
      }

      spinner.succeed('Benchmarks completed');

      // Process and display results
      const aggregatedResults = this.aggregateBenchmarkResults(results);
      this.displayBenchmarkResults(aggregatedResults, options);

      // Save results
      await this.saveBenchmarkResults(aggregatedResults, options);

    } catch (error) {
      spinner.fail(`Benchmark failed: ${error.message}`);
      process.exit(1);
    }
  }

  // Handle report command
  private async handleReport(options: any): Promise<void> {
    const spinner = ora('Generating performance report...').start();

    try {
      // Load performance data
      const data = await this.loadPerformanceData(options.input);
      
      // Generate report based on template
      const report = await this.generateReport(data, options);

      // Save report
      await this.saveReport(report, options);

      spinner.succeed(`Report generated: ${options.output}`);

    } catch (error) {
      spinner.fail(`Report generation failed: ${error.message}`);
      process.exit(1);
    }
  }

  // Handle config command
  private async handleConfig(options: any): Promise<void> {
    try {
      if (options.init) {
        await this.initializeConfig(options.output || 'performance-config.json');
        console.log(chalk.green('‚úÖ Configuration initialized'));
      }

      if (options.validate) {
        const isValid = await this.validateConfig(options.validate);
        if (isValid) {
          console.log(chalk.green('‚úÖ Configuration is valid'));
        } else {
          console.log(chalk.red('‚ùå Configuration is invalid'));
          process.exit(1);
        }
      }

      if (options.show) {
        const config = await this.loadConfiguration(options.show);
        console.log(JSON.stringify(config, null, 2));
      }

    } catch (error) {
      console.error(chalk.red(`‚ùå Config operation failed: ${error.message}`));
      process.exit(1);
    }
  }

  // Handle status command
  private async handleStatus(options: any): Promise<void> {
    try {
      const config = await this.loadConfiguration(options.config);
      this.optimizer = new PerformanceOptimizer(config);

      // Collect current metrics
      await this.sleep(1000); // Allow time for initial collection

      const status = {
        timestamp: new Date().toISOString(),
        system: {
          platform: process.platform,
          arch: process.arch,
          nodeVersion: process.version,
          memory: process.memoryUsage(),
          uptime: process.uptime()
        },
        // performance: await this.optimizer.collectMetrics()
      };

      if (options.json) {
        console.log(JSON.stringify(status, null, 2));
      } else {
        this.displayStatus(status, options.verbose);
      }

    } catch (error) {
      console.error(chalk.red(`‚ùå Status check failed: ${error.message}`));
      process.exit(1);
    }
  }

  // Helper methods

  private async loadConfiguration(configPath?: string): Promise<PerformanceOptimizerConfig> {
    // Default configuration
    const defaultConfig: PerformanceOptimizerConfig = {
      memory: {
        maxHeapSize: 2 * 1024 * 1024 * 1024, // 2GB
        gcThreshold: 80,
        enableStreaming: true,
        chunkSize: 64 * 1024, // 64KB
        memoryPoolSize: 100 * 1024 * 1024 // 100MB
      },
      cpu: {
        maxWorkers: require('os').cpus().length,
        workerIdleTimeout: 30000,
        enableClustering: false,
        priorityLevel: 'normal'
      },
      io: {
        maxConcurrentReads: 10,
        maxConcurrentWrites: 5,
        bufferSize: 64 * 1024,
        enableCompression: true,
        compressionLevel: 6
      },
      network: {
        connectionPoolSize: 100,
        keepAliveTimeout: 30000,
        maxRetries: 3,
        retryBackoff: 1.5,
        enablePipelining: false,
        maxPipelineRequests: 10
      },
      cache: {
        enabled: true,
        maxSize: 100 * 1024 * 1024, // 100MB
        ttl: 3600000, // 1 hour
        enableLRU: true,
        enableCompression: false,
        persistToDisk: false
      },
      database: {
        connectionPoolSize: 20,
        queryTimeout: 30000,
        enablePreparedStatements: true,
        batchSize: 1000,
        enableReadReplicas: false
      },
      general: {
        enableProfiling: true,
        profilingInterval: 5000,
        enableMetrics: true,
        metricsRetention: 24 * 60 * 60 * 1000, // 24 hours
        enableOptimizations: ['memory', 'cpu', 'io', 'network', 'cache']
      }
    };

    if (configPath) {
      try {
        const configFile = await fs.readFile(configPath, 'utf-8');
        const userConfig = JSON.parse(configFile);
        return { ...defaultConfig, ...userConfig };
      } catch (error) {
        console.warn(chalk.yellow(`‚ö†Ô∏è  Could not load config file: ${configPath}`));
        console.warn(chalk.yellow('Using default configuration'));
      }
    }

    return defaultConfig;
  }

  private setupEventListeners(verbose: boolean): void {
    if (!this.optimizer) return;

    this.optimizer.on('optimization-started', () => {
      if (verbose) console.log(chalk.blue('üöÄ Optimization started'));
    });

    this.optimizer.on('optimization-applying', (recommendation) => {
      if (verbose) {
        console.log(chalk.yellow(`üîß Applying: ${recommendation.title}`));
      }
    });

    this.optimizer.on('optimization-completed', (result) => {
      if (verbose) {
        const improvement = result.metrics.improvement;
        console.log(chalk.green(`‚úÖ Completed: ${result.recommendation.title}`));
        console.log(chalk.gray(`   Performance: ${improvement.performance}%, Memory: ${improvement.memory}%, CPU: ${improvement.cpu}%`));
      }
    });

    this.optimizer.on('optimization-failed', (result) => {
      console.log(chalk.red(`‚ùå Failed: ${result.recommendation.title}`));
      if (result.error) {
        console.log(chalk.red(`   Error: ${result.error}`));
      }
    });
  }

  private displayAnalysisResults(recommendations: any[], options: any): void {
    console.log(chalk.blue('\nüìä Performance Analysis Results\n'));

    if (recommendations.length === 0) {
      console.log(chalk.green('‚úÖ No optimization opportunities found. System is performing well!'));
      return;
    }

    const table = new Table({
      head: ['Priority', 'Category', 'Title', 'Impact', 'Complexity'],
      colWidths: [10, 12, 40, 15, 12]
    });

    recommendations.forEach(rec => {
      const priorityColor = {
        critical: chalk.red,
        high: chalk.yellow,
        medium: chalk.blue,
        low: chalk.gray
      }[rec.priority] || chalk.white;

      const complexityColor = {
        high: chalk.red,
        medium: chalk.yellow,
        low: chalk.green
      }[rec.implementation.complexity] || chalk.white;

      table.push([
        priorityColor(rec.priority.toUpperCase()),
        rec.category,
        rec.title,
        `P:${rec.impact.performance}% M:${rec.impact.memory}% C:${rec.impact.cpu}%`,
        complexityColor(rec.implementation.complexity)
      ]);
    });

    console.log(table.toString());

    // Summary
    const criticalCount = recommendations.filter(r => r.priority === 'critical').length;
    const highCount = recommendations.filter(r => r.priority === 'high').length;
    
    console.log(chalk.blue('\nüìà Summary:'));
    console.log(`  Total recommendations: ${recommendations.length}`);
    if (criticalCount > 0) console.log(chalk.red(`  Critical issues: ${criticalCount}`));
    if (highCount > 0) console.log(chalk.yellow(`  High priority: ${highCount}`));
  }

  private displayOptimizationResults(report: PerformanceOptimizationReport, options: any): void {
    console.log(chalk.blue('\nüéØ Performance Optimization Results\n'));

    const { summary } = report;

    // Summary table
    const summaryTable = new Table();
    summaryTable.push(
      ['Total Optimizations', summary.totalOptimizations],
      ['Successful', chalk.green(summary.successfulOptimizations.toString())],
      ['Failed', summary.failedOptimizations > 0 ? chalk.red(summary.failedOptimizations.toString()) : '0'],
      ['Performance Improvement', `${summary.overallImprovement.performance}%`],
      ['Memory Reduction', `${summary.overallImprovement.memory}%`],
      ['CPU Reduction', `${summary.overallImprovement.cpu}%`],
      ['Estimated Cost Savings', `$${summary.estimatedCostSavings}`]
    );

    console.log(summaryTable.toString());

    // Bottlenecks and next steps
    if (report.analysis.bottlenecks.length > 0) {
      console.log(chalk.yellow('\n‚ö†Ô∏è  Remaining Bottlenecks:'));
      report.analysis.bottlenecks.forEach(bottleneck => {
        console.log(`  ‚Ä¢ ${bottleneck}`);
      });
    }

    if (report.analysis.nextSteps.length > 0) {
      console.log(chalk.blue('\nüìã Next Steps:'));
      report.analysis.nextSteps.forEach(step => {
        console.log(`  ‚Ä¢ ${step}`);
      });
    }
  }

  private displayMetrics(metrics: any, progress: number, verbose: boolean): void {
    const progressBar = '‚ñà'.repeat(Math.floor(progress / 5)) + '‚ñë'.repeat(20 - Math.floor(progress / 5));
    
    console.clear();
    console.log(chalk.blue('üìä Performance Monitoring\n'));
    console.log(`Progress: [${progressBar}] ${progress}%\n`);

    const table = new Table();
    table.push(
      ['Memory Usage', `${Math.round(metrics.memory.heapUsed / 1024 / 1024)} MB`],
      ['CPU Usage', `${metrics.cpu.usage.toFixed(1)}%`],
      ['Event Loop Lag', `${metrics.eventLoop.lag.toFixed(2)} ms`],
      ['Active Connections', metrics.network.connectionsActive],
      ['Timestamp', new Date(metrics.timestamp).toLocaleTimeString()]
    );

    console.log(table.toString());

    if (verbose) {
      console.log(chalk.gray('\nDetailed Metrics:'));
      console.log(JSON.stringify(metrics, null, 2));
    }
  }

  private displayDashboard(metrics: any, progress: number): void {
    // Simplified dashboard view
    console.clear();
    console.log(chalk.blue.bold('üìä PERFORMANCE DASHBOARD\n'));
    
    const memUsage = Math.round((metrics.memory.heapUsed / metrics.memory.heapTotal) * 100);
    const cpuUsage = Math.round(metrics.cpu.usage);
    const eventLag = metrics.eventLoop.lag;

    console.log(this.createGauge('Memory', memUsage, 80));
    console.log(this.createGauge('CPU', cpuUsage, 70));
    console.log(this.createGauge('Event Loop Lag', Math.min(eventLag, 100), 50));
    
    console.log(chalk.blue(`\nProgress: ${progress}%`));
    console.log(chalk.gray(`Last Update: ${new Date().toLocaleTimeString()}`));
  }

  private createGauge(label: string, value: number, warningThreshold: number): string {
    const width = 30;
    const filled = Math.round((value / 100) * width);
    const color = value > warningThreshold ? chalk.red : value > warningThreshold * 0.8 ? chalk.yellow : chalk.green;
    
    const bar = color('‚ñà'.repeat(filled)) + '‚ñë'.repeat(width - filled);
    return `${label.padEnd(15)} [${bar}] ${value}%`;
  }

  private displayStatus(status: any, verbose: boolean): void {
    console.log(chalk.blue('üìä System Performance Status\n'));

    const table = new Table();
    table.push(
      ['Platform', `${status.system.platform} ${status.system.arch}`],
      ['Node.js Version', status.system.nodeVersion],
      ['Memory (RSS)', `${Math.round(status.system.memory.rss / 1024 / 1024)} MB`],
      ['Memory (Heap Used)', `${Math.round(status.system.memory.heapUsed / 1024 / 1024)} MB`],
      ['Memory (Heap Total)', `${Math.round(status.system.memory.heapTotal / 1024 / 1024)} MB`],
      ['Uptime', `${Math.round(status.system.uptime)} seconds`],
      ['Timestamp', status.timestamp]
    );

    console.log(table.toString());

    if (verbose && status.performance) {
      console.log(chalk.blue('\nüìà Performance Metrics:'));
      console.log(JSON.stringify(status.performance, null, 2));
    }
  }

  private async saveAnalysisResults(recommendations: any[], options: any): Promise<void> {
    const outputDir = options.output;
    await fs.mkdir(outputDir, { recursive: true });

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `performance-analysis-${timestamp}.${options.format}`;
    const outputPath = path.join(outputDir, filename);

    const data = {
      timestamp: new Date().toISOString(),
      recommendations,
      summary: {
        total: recommendations.length,
        critical: recommendations.filter(r => r.priority === 'critical').length,
        high: recommendations.filter(r => r.priority === 'high').length,
        medium: recommendations.filter(r => r.priority === 'medium').length,
        low: recommendations.filter(r => r.priority === 'low').length
      }
    };

    if (options.format === 'json') {
      await fs.writeFile(outputPath, JSON.stringify(data, null, 2));
    } else if (options.format === 'html') {
      const html = this.generateHTMLReport(data, 'analysis');
      await fs.writeFile(outputPath, html);
    }

    console.log(chalk.blue(`üìÅ Analysis results saved to: ${outputPath}`));
  }

  private async saveOptimizationResults(report: PerformanceOptimizationReport, options: any): Promise<void> {
    const outputDir = options.output;
    await fs.mkdir(outputDir, { recursive: true });

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `performance-optimization-${timestamp}.${options.format}`;
    const outputPath = path.join(outputDir, filename);

    if (options.format === 'json') {
      await fs.writeFile(outputPath, JSON.stringify(report, null, 2));
    } else if (options.format === 'html') {
      const html = this.generateHTMLReport(report, 'optimization');
      await fs.writeFile(outputPath, html);
    }

    console.log(chalk.blue(`üìÅ Optimization results saved to: ${outputPath}`));
  }

  private async runSingleBenchmark(config: PerformanceOptimizerConfig): Promise<any> {
    // Simplified benchmark implementation
    const start = process.hrtime.bigint();
    
    // Simulate some work
    await this.sleep(Math.random() * 100 + 50);
    
    const end = process.hrtime.bigint();
    const duration = Number(end - start) / 1000000; // Convert to milliseconds

    return {
      duration,
      memory: process.memoryUsage(),
      timestamp: Date.now()
    };
  }

  private aggregateBenchmarkResults(results: any[]): any {
    const durations = results.map(r => r.duration);
    const memories = results.map(r => r.memory.heapUsed);

    return {
      iterations: results.length,
      duration: {
        min: Math.min(...durations),
        max: Math.max(...durations),
        avg: durations.reduce((a, b) => a + b, 0) / durations.length,
        median: durations.sort()[Math.floor(durations.length / 2)]
      },
      memory: {
        min: Math.min(...memories),
        max: Math.max(...memories),
        avg: memories.reduce((a, b) => a + b, 0) / memories.length
      },
      timestamp: Date.now()
    };
  }

  private displayBenchmarkResults(results: any, options: any): void {
    console.log(chalk.blue('\nüèÅ Benchmark Results\n'));

    const table = new Table();
    table.push(
      ['Iterations', results.iterations],
      ['Duration (min)', `${results.duration.min.toFixed(2)} ms`],
      ['Duration (max)', `${results.duration.max.toFixed(2)} ms`],
      ['Duration (avg)', `${results.duration.avg.toFixed(2)} ms`],
      ['Duration (median)', `${results.duration.median.toFixed(2)} ms`],
      ['Memory (avg)', `${Math.round(results.memory.avg / 1024 / 1024)} MB`]
    );

    console.log(table.toString());
  }

  private async saveBenchmarkResults(results: any, options: any): Promise<void> {
    const outputDir = options.output;
    await fs.mkdir(outputDir, { recursive: true });

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `benchmark-results-${timestamp}.${options.format}`;
    const outputPath = path.join(outputDir, filename);

    if (options.format === 'json') {
      await fs.writeFile(outputPath, JSON.stringify(results, null, 2));
    } else if (options.format === 'html') {
      const html = this.generateHTMLReport(results, 'benchmark');
      await fs.writeFile(outputPath, html);
    }

    console.log(chalk.blue(`üìÅ Benchmark results saved to: ${outputPath}`));
  }

  private async loadPerformanceData(inputPath: string): Promise<any> {
    // Load performance data from file or directory
    try {
      const stats = await fs.stat(inputPath);
      if (stats.isDirectory()) {
        // Load all JSON files from directory
        const files = await fs.readdir(inputPath);
        const jsonFiles = files.filter(f => f.endsWith('.json'));
        const data = [];
        
        for (const file of jsonFiles) {
          const content = await fs.readFile(path.join(inputPath, file), 'utf-8');
          data.push(JSON.parse(content));
        }
        
        return data;
      } else {
        // Load single file
        const content = await fs.readFile(inputPath, 'utf-8');
        return JSON.parse(content);
      }
    } catch (error) {
      throw new Error(`Could not load performance data: ${error.message}`);
    }
  }

  private async generateReport(data: any, options: any): Promise<any> {
    // Generate report based on template and format
    return {
      template: options.template,
      format: options.format,
      data,
      timestamp: new Date().toISOString()
    };
  }

  private async saveReport(report: any, options: any): Promise<void> {
    const outputDir = options.output;
    await fs.mkdir(outputDir, { recursive: true });

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `performance-report-${timestamp}.${options.format}`;
    const outputPath = path.join(outputDir, filename);

    if (options.format === 'json') {
      await fs.writeFile(outputPath, JSON.stringify(report, null, 2));
    } else if (options.format === 'html') {
      const html = this.generateHTMLReport(report, 'report');
      await fs.writeFile(outputPath, html);
    }

    console.log(chalk.blue(`üìÅ Report saved to: ${outputPath}`));
  }

  private async initializeConfig(outputPath: string): Promise<void> {
    const defaultConfig = await this.loadConfiguration();
    await fs.writeFile(outputPath, JSON.stringify(defaultConfig, null, 2));
  }

  private async validateConfig(configPath: string): Promise<boolean> {
    try {
      await this.loadConfiguration(configPath);
      return true;
    } catch {
      return false;
    }
  }

  private generateHTMLReport(data: any, type: string): string {
    // Simple HTML report template
    return `
<!DOCTYPE html>
<html>
<head>
    <title>Performance ${type.charAt(0).toUpperCase() + type.slice(1)} Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .header { border-bottom: 2px solid #333; padding-bottom: 20px; }
        .section { margin: 30px 0; }
        .metric { background: #f5f5f5; padding: 10px; margin: 10px 0; border-radius: 5px; }
        table { width: 100%; border-collapse: collapse; }
        th, td { padding: 10px; border: 1px solid #ddd; text-align: left; }
        th { background-color: #f2f2f2; }
        .success { color: green; }
        .warning { color: orange; }
        .error { color: red; }
    </style>
</head>
<body>
    <div class="header">
        <h1>Performance ${type.charAt(0).toUpperCase() + type.slice(1)} Report</h1>
        <p>Generated: ${new Date().toLocaleString()}</p>
    </div>
    
    <div class="section">
        <h2>Data</h2>
        <pre>${JSON.stringify(data, null, 2)}</pre>
    </div>
</body>
</html>
    `;
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // Run the CLI
  public run(): void {
    this.program.parse(process.argv);
  }
}

// Export for use as a module
export default PerformanceCLI;

// If run directly, execute the CLI
if (require.main === module) {
  const cli = new PerformanceCLI();
  cli.run();
}