"""
Advanced Error Scenario Test Generator

Generates comprehensive error scenario tests covering all HTTP error codes,
boundary conditions, and edge cases based on API specifications.
"""

import json
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from pathlib import Path
from src.config.settings import Settings
import structlog

logger = structlog.get_logger()

@dataclass
class ErrorScenario:
    """Represents a specific error scenario to test"""
    name: str
    description: str
    expected_status_code: int
    test_payload: Dict[str, Any]
    test_headers: Optional[Dict[str, str]] = None
    test_params: Optional[Dict[str, str]] = None
    test_method_override: Optional[str] = None

class ErrorScenarioGenerator:
    """
    Generates comprehensive error scenario tests for API endpoints
    """
    
    def __init__(self):
        self.logger = structlog.get_logger()
    
    def generate_error_scenarios(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """
        Generate all error scenarios for an API endpoint
        
        Args:
            api_spec: API specification dictionary
            
        Returns:
            List of ErrorScenario objects
        """
        scenarios = []
        
        # Add HTTP method-specific scenarios
        scenarios.extend(self._generate_method_errors(api_spec))
        
        # Add authentication/authorization errors
        scenarios.extend(self._generate_auth_errors(api_spec))
        
        # Add validation errors based on schema
        scenarios.extend(self._generate_validation_errors(api_spec))
        
        # Add boundary value errors
        scenarios.extend(self._generate_boundary_errors(api_spec))
        
        # Add content type errors
        scenarios.extend(self._generate_content_type_errors(api_spec))
        
        # Add rate limiting scenarios
        scenarios.extend(self._generate_rate_limit_errors(api_spec))
        
        # Add server error scenarios
        scenarios.extend(self._generate_server_errors(api_spec))
        
        self.logger.info(f"Generated {len(scenarios)} error scenarios for {api_spec.get('path')}")
        return scenarios
    
    def _generate_method_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate method not allowed errors"""
        scenarios = []
        
        allowed_method = api_spec.get('method', 'GET')
        forbidden_methods = ['GET', 'POST', 'PUT', 'PATCH', 'DELETE', 'HEAD', 'OPTIONS']
        forbidden_methods = [m for m in forbidden_methods if m != allowed_method]
        
        for method in forbidden_methods[:3]:  # Test first 3 forbidden methods
            scenarios.append(ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_method_{method.lower()}_not_allowed",
                description=f"Test {method} method returns 405 Method Not Allowed",
                expected_status_code=405,
                test_payload={},
                test_method_override=method
            ))
        
        return scenarios
    
    def _generate_auth_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate authentication and authorization error scenarios"""
        scenarios = []
        
        # 401 Unauthorized scenarios
        scenarios.extend([
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_missing_auth",
                description="Test request without authentication returns 401",
                expected_status_code=401,
                test_payload={"test": "data"}
            ),
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_invalid_token",
                description="Test request with invalid token returns 401",
                expected_status_code=401,
                test_payload={"test": "data"},
                test_headers={"Authorization": "Bearer invalid_token_placeholder"}
            ),
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_expired_token",
                description="Test request with expired token returns 401",
                expected_status_code=401,
                test_payload={"test": "data"},
                test_headers={"Authorization": "Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDk0NTkyMDB9.expired"}
            ),
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_malformed_auth_header",
                description="Test request with malformed Authorization header returns 401",
                expected_status_code=401,
                test_payload={"test": "data"},
                test_headers={"Authorization": "InvalidFormat token"}
            )
        ])
        
        # 403 Forbidden scenarios
        scenarios.extend([
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_insufficient_permissions",
                description="Test request with insufficient permissions returns 403",
                expected_status_code=403,
                test_payload={"test": "data"},
                test_headers={"Authorization": "Bearer {settings.test_limited_token or 'limited_placeholder'}"}
            ),
            ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_revoked_token",
                description="Test request with revoked token returns 403",
                expected_status_code=403,
                test_payload={"test": "data"},
                test_headers={"Authorization": "Bearer {settings.test_revoked_token or 'revoked_placeholder'}"}
            )
        ])
        
        return scenarios
    
    def _generate_validation_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate validation error scenarios based on request schema"""
        scenarios = []
        
        request_body = api_spec.get('request_body', {})
        if not request_body:
            return scenarios
            
        schema = request_body.get('content', {}).get('application/json', {}).get('schema', {})
        properties = schema.get('properties', {})
        required_fields = schema.get('required', [])
        
        # Missing required fields
        for field in required_fields:
            invalid_payload = {k: f"test_{k}" for k in properties.keys() if k != field}
            scenarios.append(ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_missing_{field}",
                description=f"Test request missing required field '{field}' returns 400",
                expected_status_code=400,
                test_payload=invalid_payload
            ))
        
        # Invalid field types
        for field_name, field_spec in properties.items():
            field_type = field_spec.get('type', 'string')
            invalid_value = self._get_invalid_type_value(field_type)
            
            if invalid_value is not None:
                valid_payload = {k: f"test_{k}" for k in properties.keys()}
                valid_payload[field_name] = invalid_value
                
                scenarios.append(ErrorScenario(
                    name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_invalid_{field_name}_type",
                    description=f"Test request with invalid {field_name} type returns 400",
                    expected_status_code=400,
                    test_payload=valid_payload
                ))
        
        # Empty payload when fields are required
        if required_fields:
            scenarios.append(ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_empty_payload",
                description="Test request with empty payload returns 400",
                expected_status_code=400,
                test_payload={}
            ))
        
        return scenarios
    
    def _generate_boundary_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate boundary value error scenarios"""
        scenarios = []
        
        request_body = api_spec.get('request_body', {})
        if not request_body:
            return scenarios
            
        schema = request_body.get('content', {}).get('application/json', {}).get('schema', {})
        properties = schema.get('properties', {})
        
        for field_name, field_spec in properties.items():
            field_type = field_spec.get('type', 'string')
            
            # String length boundaries
            if field_type == 'string':
                max_length = field_spec.get('maxLength')
                min_length = field_spec.get('minLength', 0)
                
                if max_length:
                    # Test string too long
                    valid_payload = {k: f"test_{k}" for k in properties.keys()}
                    valid_payload[field_name] = "x" * (max_length + 1)
                    
                    scenarios.append(ErrorScenario(
                        name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_{field_name}_too_long",
                        description=f"Test {field_name} exceeding max length returns 400",
                        expected_status_code=400,
                        test_payload=valid_payload
                    ))
                
                if min_length > 0:
                    # Test string too short
                    valid_payload = {k: f"test_{k}" for k in properties.keys()}
                    valid_payload[field_name] = "x" * max(0, min_length - 1)
                    
                    scenarios.append(ErrorScenario(
                        name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_{field_name}_too_short",
                        description=f"Test {field_name} below min length returns 400",
                        expected_status_code=400,
                        test_payload=valid_payload
                    ))
            
            # Numeric boundaries
            elif field_type in ['integer', 'number']:
                minimum = field_spec.get('minimum')
                maximum = field_spec.get('maximum')
                
                if minimum is not None:
                    # Test value below minimum
                    valid_payload = {k: f"test_{k}" for k in properties.keys()}
                    valid_payload[field_name] = minimum - 1
                    
                    scenarios.append(ErrorScenario(
                        name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_{field_name}_below_minimum",
                        description=f"Test {field_name} below minimum returns 400",
                        expected_status_code=400,
                        test_payload=valid_payload
                    ))
                
                if maximum is not None:
                    # Test value above maximum
                    valid_payload = {k: f"test_{k}" for k in properties.keys()}
                    valid_payload[field_name] = maximum + 1
                    
                    scenarios.append(ErrorScenario(
                        name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_{field_name}_above_maximum",
                        description=f"Test {field_name} above maximum returns 400",
                        expected_status_code=400,
                        test_payload=valid_payload
                    ))
        
        return scenarios
    
    def _generate_content_type_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate content type error scenarios"""
        scenarios = []
        
        # Wrong Content-Type header
        scenarios.append(ErrorScenario(
            name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_wrong_content_type",
            description="Test request with wrong Content-Type returns 415",
            expected_status_code=415,
            test_payload={"test": "data"},
            test_headers={"Content-Type": "text/plain"}
        ))
        
        # Missing Content-Type for POST/PUT/PATCH
        if api_spec.get('method') in ['POST', 'PUT', 'PATCH']:
            scenarios.append(ErrorScenario(
                name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_missing_content_type",
                description="Test request without Content-Type returns 400",
                expected_status_code=400,
                test_payload={"test": "data"},
                test_headers={"Content-Type": ""}
            ))
        
        return scenarios
    
    def _generate_rate_limit_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate rate limiting error scenarios"""
        scenarios = []
        
        # Rate limiting test (429 Too Many Requests)
        scenarios.append(ErrorScenario(
            name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_rate_limit_exceeded",
            description="Test rapid requests trigger rate limiting (429)",
            expected_status_code=429,
            test_payload={"test": "data"}
        ))
        
        return scenarios
    
    def _generate_server_errors(self, api_spec: Dict[str, Any]) -> List[ErrorScenario]:
        """Generate server error scenarios"""
        scenarios = []
        
        # Test with oversized payload (413 Payload Too Large)
        scenarios.append(ErrorScenario(
            name=f"test_{api_spec.get('operationId', 'endpoint').lower()}_payload_too_large",
            description="Test oversized payload returns 413",
            expected_status_code=413,
            test_payload={"large_data": "x" * 1000000}  # 1MB of data
        ))
        
        return scenarios
    
    def _get_invalid_type_value(self, field_type: str) -> Any:
        """Get an invalid value for a given field type"""
        type_invalid_values = {
            'string': 12345,  # number instead of string
            'integer': "not_a_number",  # string instead of integer
            'number': "not_a_number",  # string instead of number
            'boolean': "not_a_boolean",  # string instead of boolean
            'array': "not_an_array",  # string instead of array
            'object': "not_an_object"  # string instead of object
        }
        
        return type_invalid_values.get(field_type)
    
    def generate_test_file(self, api_spec: Dict[str, Any], output_dir: str) -> str:
        """
        Generate a complete error scenario test file
        
        Args:
            api_spec: API specification dictionary
            output_dir: Directory to save the test file
            
        Returns:
            Path to the generated test file
        """
        scenarios = self.generate_error_scenarios(api_spec)
        
        # Generate test file content
        test_content = self._generate_test_file_content(api_spec, scenarios)
        
        # Save to file
        operation_id = api_spec.get('operationId', 'endpoint').lower()
        filename = f"test_{operation_id}_error_scenarios.py"
        output_path = Path(output_dir) / filename
        
        with open(output_path, 'w') as f:
            f.write(test_content)
        
        self.logger.info(f"Generated error scenario test file: {output_path}")
        return str(output_path)
    
    def _generate_test_file_content(self, api_spec: Dict[str, Any], scenarios: List[ErrorScenario]) -> str:
        """Generate the actual test file content"""
        operation_id = api_spec.get('operationId', 'endpoint')
        method = api_spec.get('method', 'GET')
        path = api_spec.get('path', '/api/endpoint')
        description = api_spec.get('description', f'{operation_id} endpoint')
        
        # Build content using string concatenation to avoid f-string brace conflicts
        imports_section = """import pytest
import httpx
from typing import Dict, Any, Optional
import json
import asyncio
from src.config.settings import Settings

"""
        
        header_section = f"""# Advanced Error Scenario Tests for: {description}
# Method: {method}
# Path: {path}
# Generated: Week 3 Advanced Test Generation

# Load settings from environment
settings = Settings()
BASE_URL = settings.test_api_base_url

"""
        
        class_section = f"""class Test{operation_id.title().replace('_', '')}ErrorScenarios:
    
    @pytest.fixture
    def client(self):
        cookies = self._get_cookies()
        return httpx.AsyncClient(base_url=BASE_URL, cookies=cookies, timeout=30.0)
    
    def _get_cookies(self):
        cookies = {}
        if settings.test_cookie_connect_sid:
            cookies['connect.sid'] = settings.test_cookie_connect_sid
        return cookies
    
    @pytest.fixture
    def auth_headers(self):
        """Various authentication headers for testing"""
        return {
            "valid": {"Authorization": f"Bearer {settings.test_auth_token}"},
            "invalid": {"Authorization": "Bearer invalid_token_placeholder"},
            "expired": {"Authorization": "Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MDk0NTkyMDB9.expired"},
            "malformed": {"Authorization": "InvalidFormat token"},
            "limited": {"Authorization": f"Bearer {settings.test_limited_token or 'limited_placeholder'}"},
            "revoked": {"Authorization": f"Bearer {settings.test_revoked_token or 'revoked_placeholder'}"}
        }

"""
        
        content = imports_section + header_section + class_section
        
        # Generate test methods for each scenario
        for scenario in scenarios:
            content += self._generate_test_method(scenario, api_spec)
            content += "\n"
        
        # Add batch testing method for performance
        content += self._generate_batch_error_test(api_spec, scenarios)
        
        return content
    
    def _generate_test_method(self, scenario: ErrorScenario, api_spec: Dict[str, Any]) -> str:
        """Generate a single test method for an error scenario"""
        method = scenario.test_method_override or api_spec.get('method', 'GET')
        path = api_spec.get('path', '/api/endpoint')
        
        method_code = f'''    @pytest.mark.asyncio
    async def {scenario.name}(self, client):
        \"\"\"{scenario.description}\"\"\"
'''
        
        # Add headers if specified
        if scenario.test_headers:
            headers_str = json.dumps(scenario.test_headers, indent=8)[:-1] + "    }"
            method_code += f"        headers = {headers_str}\n"
        else:
            method_code += "        headers = {}\n"
        
        # Add parameters if specified
        if scenario.test_params:
            params_str = json.dumps(scenario.test_params, indent=8)[:-1] + "    }"
            method_code += f"        params = {params_str}\n"
        else:
            method_code += "        params = {}\n"
        
        # Generate the request
        if method.upper() in ['POST', 'PUT', 'PATCH']:
            payload_str = json.dumps(scenario.test_payload, indent=8)[:-1] + "    }" if scenario.test_payload else "{}"
            method_code += f'''        payload = {payload_str}
        
        response = await client.{method.lower()}(
            "{path}",
            json=payload,
            headers=headers,
            params=params
        )
'''
        else:
            method_code += f'''        
        response = await client.{method.lower()}(
            "{path}",
            headers=headers,
            params=params
        )
'''
        
        # Add assertions
        if scenario.expected_status_code == 429:
            # Special handling for rate limiting tests
            method_code += f'''        
        # For rate limiting, send multiple rapid requests
        responses = []
        for i in range(10):
            try:
                resp = await client.{method.lower()}("{path}", json=payload if 'payload' in locals() else {{}}, headers=headers)
                responses.append(resp)
                if resp.status_code == 429:
                    break
            except Exception:
                break
        
        # Check if any request was rate limited
        rate_limited = any(r.status_code == 429 for r in responses)
        
        # Either rate limiting triggered, or all requests succeeded
        if rate_limited:
            assert any(r.status_code == 429 for r in responses)
        else:
            # If no rate limiting, just ensure valid responses
            for resp in responses:
                assert 200 <= resp.status_code < 600
'''
        elif scenario.expected_status_code == 413:
            # Special handling for payload too large
            method_code += f'''        
        try:
            # Should return 413 Payload Too Large or similar error
            assert response.status_code in [413, 400, 422], f"Expected 413/400/422, got {{response.status_code}}"
        except httpx.RequestEntityTooLarge:
            # Client-side validation caught it first
            pass
        except Exception as e:
            # Network-level errors are acceptable for oversized payloads
            assert "413" in str(e) or "too large" in str(e).lower() or "entity" in str(e).lower()
'''
        else:
            # Standard error code assertion
            method_code += f'''        
        # Verify expected error response
        assert response.status_code == {scenario.expected_status_code}, \\
            f"Expected {scenario.expected_status_code}, got {{response.status_code}}. Response: {{response.text}}"
        
        # Verify response content type for error responses
        if response.status_code >= 400:
            content_type = response.headers.get("content-type", "")
            # Most APIs return JSON error responses
            if content_type and "json" in content_type.lower():
                try:
                    error_data = response.json()
                    assert isinstance(error_data, dict), "Error response should be a JSON object"
                except json.JSONDecodeError:
                    pass  # Some APIs return non-JSON error responses
'''
        
        return method_code
    
    def _generate_batch_error_test(self, api_spec: Dict[str, Any], scenarios: List[ErrorScenario]) -> str:
        """Generate a batch test method for testing multiple error scenarios efficiently"""
        operation_id = api_spec.get('operationId', 'endpoint').lower()
        
        batch_test_content = f'''    @pytest.mark.asyncio
    async def test_{operation_id}_batch_error_scenarios(self, client):
        \"\"\"Batch test multiple error scenarios for efficiency\"\"\"
        
        # Define error scenarios for batch testing
        error_scenarios = [
            # Authentication errors
            {{"payload": {{"test": "data"}}, "headers": {{}}, "expected": [401, 403]}},
            {{"payload": {{"test": "data"}}, "headers": {{"Authorization": "Bearer invalid"}}, "expected": [401, 403]}},
            
            # Validation errors
            {{"payload": {{}}, "headers": {{}}, "expected": [400, 422]}},
            {{"payload": {{"invalid_field": "value"}}, "headers": {{}}, "expected": [400, 422]}},
            
            # Content type errors
            {{"payload": {{"test": "data"}}, "headers": {{"Content-Type": "text/plain"}}, "expected": [415, 400]}},
        ]
        
        results = []
        for scenario in error_scenarios:
            try:
                response = await client.{api_spec.get('method', 'get').lower()}(
                    "{api_spec.get('path', '/api/endpoint')}",
                    json=scenario["payload"],
                    headers=scenario["headers"]
                )
                
                results.append({{
                    "status_code": response.status_code,
                    "expected": scenario["expected"],
                    "success": response.status_code in scenario["expected"]
                }})
                
            except Exception as e:
                # Some errors might be caught at client level
                results.append({{
                    "status_code": None,
                    "expected": scenario["expected"],
                    "success": True,  # Client-level errors are acceptable
                    "error": str(e)
                }})
        
        # Analyze results
        successful_tests = sum(1 for r in results if r["success"])
        total_tests = len(results)
        
        # At least 70% of error scenarios should behave as expected
        success_rate = successful_tests / total_tests if total_tests > 0 else 0
        assert success_rate >= 0.7, f"Error scenario success rate too low: {{success_rate:.2%}} ({{successful_tests}}/{{total_tests}})"
        
        # Log results for debugging
        print(f"\\nBatch Error Test Results:")
        for i, result in enumerate(results):
            print(f"  Scenario {{i+1}}: Status={{result.get('status_code', 'Error')}}, Expected={{result['expected']}}, Success={{result['success']}}")
'''
        
        return batch_test_content