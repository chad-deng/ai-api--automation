"""
Enhanced Test Generator Adapter

Integrates the external enhanced_test_generator.py into the existing
test generation framework with quality control and monitoring.
"""

import asyncio
import structlog
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import sys
import os
import json
from datetime import datetime

# Add project root to Python path for importing enhanced generator
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from enhanced_test_generator import EnhancedTestGenerator, APISpec, APIField, parse_api_spec
from src.generators.quality_checker import TestQualityChecker, TestQualityReport
from src.generators.config_manager import get_config_manager, TestType
from src.webhook.schemas import ApiFoxWebhook

logger = structlog.get_logger()

@dataclass
class EnhancedGenerationResult:
    """Result of enhanced test generation with quality metrics"""
    success: bool
    generated_files: List[str]
    quality_reports: List[TestQualityReport]
    quality_summary: Dict[str, Any]
    generation_time_seconds: float
    error_message: Optional[str] = None
    fallback_used: bool = False
    metrics: Dict[str, Any] = None

class EnhancedGeneratorAdapter:
    """
    Adapter for integrating EnhancedTestGenerator with existing framework
    
    Features:
    - Quality gate enforcement (90%+ quality threshold)
    - Fallback to standard generator on failure
    - Feature flag support for gradual rollout
    - Comprehensive monitoring and metrics
    - Zero-downtime deployment support
    """
    
    def __init__(self):
        self.logger = structlog.get_logger()
        self.config_manager = get_config_manager()
        self.quality_checker = TestQualityChecker()
        self.enhanced_generator = EnhancedTestGenerator()
        
        # Performance tracking
        self.generation_metrics = {
            'total_generations': 0,
            'successful_generations': 0,
            'quality_gate_failures': 0,
            'fallback_usage': 0,
            'average_generation_time': 0.0,
            'average_quality_score': 0.0
        }
    
    async def generate_enhanced_tests(
        self, 
        webhook: ApiFoxWebhook, 
        fallback_callback=None
    ) -> EnhancedGenerationResult:
        """
        Generate tests using enhanced generator with quality control
        
        Args:
            webhook: ApiFox webhook data
            fallback_callback: Optional callback for fallback generation
            
        Returns:
            Enhanced generation result with quality metrics
        """
        start_time = datetime.now()
        self.generation_metrics['total_generations'] += 1
        
        try:
            self.logger.info(
                "Starting enhanced test generation with quality control",
                event_id=webhook.event_id,
                enhanced_engine=True
            )
            
            # Convert webhook to enhanced generator format
            api_spec = self._convert_webhook_to_api_spec(webhook)
            if not api_spec:
                raise ValueError("Failed to convert webhook to API specification")
            
            # Check if enhanced generation is enabled via feature flag
            if not self._is_enhanced_generation_enabled():
                self.logger.info("Enhanced generation disabled, using fallback")
                return await self._use_fallback_generation(webhook, fallback_callback)
            
            # Generate tests using enhanced generator
            generated_files = self.enhanced_generator.generate_comprehensive_tests(
                api_spec, 
                self.config_manager.config.output_directory
            )
            
            if not generated_files:
                raise ValueError("No files generated by enhanced generator")
            
            # Perform quality checks on all generated files
            quality_reports = []
            for file_path in generated_files:
                quality_report = self.quality_checker.check_test_file(file_path)
                quality_reports.append(quality_report)
            
            # Calculate quality summary
            quality_summary = self.quality_checker.generate_quality_summary(quality_reports)
            
            # Apply quality gate
            quality_gate_passed, gate_reason = self._check_quality_gate(
                quality_reports, quality_summary
            )
            
            if not quality_gate_passed:
                self.generation_metrics['quality_gate_failures'] += 1
                self.logger.warning(
                    "Enhanced generation failed quality gate",
                    event_id=webhook.event_id,
                    reason=gate_reason,
                    avg_quality_score=quality_summary.get('average_quality_score', 0)
                )
                
                # Move failed files to quarantine
                await self._quarantine_files(generated_files, "quality_gate_failure")
                
                # Use fallback generation
                if fallback_callback:
                    return await self._use_fallback_generation(webhook, fallback_callback)
                else:
                    raise ValueError(f"Quality gate failed: {gate_reason}")
            
            # Update metrics on success
            generation_time = (datetime.now() - start_time).total_seconds()
            self.generation_metrics['successful_generations'] += 1
            self._update_performance_metrics(generation_time, quality_summary)
            
            result = EnhancedGenerationResult(
                success=True,
                generated_files=generated_files,
                quality_reports=quality_reports,
                quality_summary=quality_summary,
                generation_time_seconds=generation_time,
                metrics=self._get_current_metrics()
            )
            
            self.logger.info(
                "Enhanced test generation completed successfully",
                event_id=webhook.event_id,
                files_generated=len(generated_files),
                quality_score=quality_summary.get('average_quality_score', 0),
                generation_time=generation_time
            )
            
            return result
            
        except Exception as e:
            generation_time = (datetime.now() - start_time).total_seconds()
            self.logger.error(
                "Enhanced test generation failed",
                event_id=webhook.event_id,
                error=str(e),
                generation_time=generation_time,
                exc_info=True
            )
            
            # Try fallback generation
            if fallback_callback:
                self.generation_metrics['fallback_usage'] += 1
                return await self._use_fallback_generation(webhook, fallback_callback)
            
            return EnhancedGenerationResult(
                success=False,
                generated_files=[],
                quality_reports=[],
                quality_summary={},
                generation_time_seconds=generation_time,
                error_message=str(e),
                metrics=self._get_current_metrics()
            )
    
    def _convert_webhook_to_api_spec(self, webhook: ApiFoxWebhook) -> Optional[APISpec]:
        """Convert ApiFox webhook to enhanced generator API spec"""
        try:
            # Extract API data from webhook
            api_data = webhook.data.get('api', {})
            
            # Create JSON structure expected by parse_api_spec
            json_data = {
                'name': api_data.get('name', 'Unknown API'),
                'method': api_data.get('method', 'GET'),
                'path': api_data.get('path', '/'),
                'description': api_data.get('description', ''),
                'requestBody': api_data.get('requestBody', {}),
                'responses': api_data.get('responses', {})
            }
            
            # Parse using enhanced generator's parser
            api_spec = parse_api_spec(json_data)
            
            self.logger.info(
                "Converted webhook to API spec",
                api_name=api_spec.name,
                method=api_spec.method,
                path=api_spec.path,
                request_fields=len(api_spec.request_fields)
            )
            
            return api_spec
            
        except Exception as e:
            self.logger.error(
                "Failed to convert webhook to API spec",
                webhook_id=webhook.event_id,
                error=str(e)
            )
            return None
    
    def _is_enhanced_generation_enabled(self) -> bool:
        """Check if enhanced generation is enabled via feature flag"""
        # Check environment variable for feature flag
        enhanced_enabled = os.getenv('ENABLE_ENHANCED_GENERATION', 'true').lower()
        
        if enhanced_enabled in ['false', '0', 'no', 'off']:
            return False
        
        # Check configuration
        config = self.config_manager.config
        
        # Check if comprehensive test types are enabled
        enhanced_test_types = [
            TestType.ERROR_SCENARIOS,
            TestType.BOUNDARY_TESTING,
            TestType.VALIDATION
        ]
        
        enabled_enhanced = any(
            test_type in config.enabled_test_types 
            for test_type in enhanced_test_types
        )
        
        return enabled_enhanced
    
    def _check_quality_gate(
        self, 
        quality_reports: List[TestQualityReport],
        quality_summary: Dict[str, Any]
    ) -> tuple[bool, str]:
        """
        Check if generated tests pass the quality gate
        
        Returns:
            Tuple of (passed, reason)
        """
        min_quality_score = self.config_manager.config.quality.min_quality_score
        
        # Check average quality score
        avg_quality_score = quality_summary.get('average_quality_score', 0.0)
        if avg_quality_score < min_quality_score:
            return False, f"Average quality score {avg_quality_score:.2%} below threshold {min_quality_score:.2%}"
        
        # Check for critical errors
        error_count = quality_summary.get('error_count', 0)
        if error_count > 0:
            return False, f"Critical errors found: {error_count}"
        
        # Check individual file quality scores
        low_quality_files = quality_summary.get('low_quality_files', 0)
        if low_quality_files > len(quality_reports) * 0.2:  # More than 20% low quality
            return False, f"Too many low quality files: {low_quality_files}/{len(quality_reports)}"
        
        # Check for files with syntax errors
        syntax_error_files = [
            report for report in quality_reports 
            if any(issue.category == 'syntax' and issue.severity == 'error' 
                   for issue in report.issues)
        ]
        
        if syntax_error_files:
            return False, f"Syntax errors in {len(syntax_error_files)} files"
        
        return True, "All quality checks passed"
    
    async def _quarantine_files(self, file_paths: List[str], reason: str):
        """Move files to quarantine directory"""
        quarantine_dir = Path(self.config_manager.config.output_directory) / 'quarantine'
        quarantine_dir.mkdir(parents=True, exist_ok=True)
        
        quarantine_reason_dir = quarantine_dir / reason
        quarantine_reason_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for file_path in file_paths:
            if Path(file_path).exists():
                quarantine_file = quarantine_reason_dir / f"{timestamp}_{Path(file_path).name}"
                try:
                    Path(file_path).rename(quarantine_file)
                    self.logger.info(f"Moved file to quarantine: {quarantine_file}")
                except Exception as e:
                    self.logger.error(f"Failed to quarantine file {file_path}: {e}")
    
    async def _use_fallback_generation(
        self, 
        webhook: ApiFoxWebhook, 
        fallback_callback
    ) -> EnhancedGenerationResult:
        """Use fallback generation when enhanced generation fails"""
        if not fallback_callback:
            return EnhancedGenerationResult(
                success=False,
                generated_files=[],
                quality_reports=[],
                quality_summary={},
                generation_time_seconds=0.0,
                error_message="No fallback available",
                fallback_used=True
            )
        
        try:
            start_time = datetime.now()
            
            self.logger.info(
                "Using fallback generation",
                event_id=webhook.event_id,
                fallback_used=True
            )
            
            # Call fallback generation
            await fallback_callback(webhook)
            
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedGenerationResult(
                success=True,
                generated_files=[],  # Fallback doesn't return file list
                quality_reports=[],
                quality_summary={},
                generation_time_seconds=generation_time,
                fallback_used=True,
                metrics=self._get_current_metrics()
            )
            
        except Exception as e:
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return EnhancedGenerationResult(
                success=False,
                generated_files=[],
                quality_reports=[],
                quality_summary={},
                generation_time_seconds=generation_time,
                error_message=f"Fallback also failed: {str(e)}",
                fallback_used=True,
                metrics=self._get_current_metrics()
            )
    
    def _update_performance_metrics(self, generation_time: float, quality_summary: Dict[str, Any]):
        """Update performance tracking metrics"""
        # Update average generation time
        total_gens = self.generation_metrics['total_generations']
        current_avg = self.generation_metrics['average_generation_time']
        self.generation_metrics['average_generation_time'] = (
            (current_avg * (total_gens - 1) + generation_time) / total_gens
        )
        
        # Update average quality score
        avg_quality = quality_summary.get('average_quality_score', 0.0)
        successful_gens = self.generation_metrics['successful_generations']
        current_quality_avg = self.generation_metrics['average_quality_score']
        self.generation_metrics['average_quality_score'] = (
            (current_quality_avg * (successful_gens - 1) + avg_quality) / successful_gens
        )
    
    def _get_current_metrics(self) -> Dict[str, Any]:
        """Get current performance metrics"""
        total_gens = self.generation_metrics['total_generations']
        
        return {
            **self.generation_metrics,
            'success_rate': (
                self.generation_metrics['successful_generations'] / total_gens 
                if total_gens > 0 else 0.0
            ),
            'quality_gate_failure_rate': (
                self.generation_metrics['quality_gate_failures'] / total_gens 
                if total_gens > 0 else 0.0
            ),
            'fallback_usage_rate': (
                self.generation_metrics['fallback_usage'] / total_gens 
                if total_gens > 0 else 0.0
            )
        }
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get health status for monitoring"""
        metrics = self._get_current_metrics()
        
        # Determine health status
        success_rate = metrics['success_rate']
        quality_score = metrics['average_quality_score']
        
        if success_rate >= 0.95 and quality_score >= 0.8:
            health = 'healthy'
        elif success_rate >= 0.8 and quality_score >= 0.7:
            health = 'degraded'
        else:
            health = 'unhealthy'
        
        return {
            'health': health,
            'enhanced_generation_enabled': self._is_enhanced_generation_enabled(),
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }
    
    async def test_enhanced_generation(self, sample_api_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Test enhanced generation with sample data for health checks
        
        Args:
            sample_api_data: Sample API specification for testing
            
        Returns:
            Test result with metrics
        """
        try:
            # Create test API spec
            api_spec = parse_api_spec(sample_api_data)
            
            # Generate tests
            start_time = datetime.now()
            generated_files = self.enhanced_generator.generate_comprehensive_tests(
                api_spec, 
                "/tmp/test_enhanced_generation"
            )
            generation_time = (datetime.now() - start_time).total_seconds()
            
            # Quick quality check
            if generated_files:
                quality_report = self.quality_checker.check_test_file(generated_files[0])
                quality_score = quality_report.quality_score
            else:
                quality_score = 0.0
            
            # Cleanup test files
            for file_path in generated_files:
                try:
                    Path(file_path).unlink(missing_ok=True)
                except Exception:
                    pass
            
            return {
                'success': True,
                'files_generated': len(generated_files),
                'generation_time_seconds': generation_time,
                'quality_score': quality_score,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }